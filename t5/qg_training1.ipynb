{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FvBm_K5WnVj9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UDaysJyJytAs"
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config,  AutoTokenizer, AutoModelWithLMHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzW_zmk2qFHG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.8\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a7a06935542990198eaf050</td>\n",
       "      <td>Which magazine was started first Arthur's Maga...</td>\n",
       "      <td>&lt;answer&gt; Arthur's Magazine &lt;context&gt; Arthur's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a879ab05542996e4f30887e</td>\n",
       "      <td>The Oberoi family is part of a hotel company t...</td>\n",
       "      <td>&lt;answer&gt; Delhi &lt;context&gt; The Oberoi family is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a8d7341554299441c6b9fe5</td>\n",
       "      <td>Musician and satirist Allie Goertz wrote a son...</td>\n",
       "      <td>&lt;answer&gt; President Richard Nixon &lt;context&gt; All...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5a82171f5542990a1d231f4a</td>\n",
       "      <td>What nationality was James Henry Miller's wife?</td>\n",
       "      <td>&lt;answer&gt; American &lt;context&gt; Margaret Peggy See...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5a84dd955542997b5ce3ff79</td>\n",
       "      <td>Cadmium Chloride is slightly soluble in this c...</td>\n",
       "      <td>&lt;answer&gt; alcohol &lt;context&gt;  It is a hygroscopi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Unnamed: 0  \\\n",
       "0  5a7a06935542990198eaf050   \n",
       "1  5a879ab05542996e4f30887e   \n",
       "2  5a8d7341554299441c6b9fe5   \n",
       "3  5a82171f5542990a1d231f4a   \n",
       "4  5a84dd955542997b5ce3ff79   \n",
       "\n",
       "                                            question  \\\n",
       "0  Which magazine was started first Arthur's Maga...   \n",
       "1  The Oberoi family is part of a hotel company t...   \n",
       "2  Musician and satirist Allie Goertz wrote a son...   \n",
       "3    What nationality was James Henry Miller's wife?   \n",
       "4  Cadmium Chloride is slightly soluble in this c...   \n",
       "\n",
       "                                                text  \n",
       "0  <answer> Arthur's Magazine <context> Arthur's ...  \n",
       "1  <answer> Delhi <context> The Oberoi family is ...  \n",
       "2  <answer> President Richard Nixon <context> All...  \n",
       "3  <answer> American <context> Margaret Peggy See...  \n",
       "4  <answer> alcohol <context>  It is a hygroscopi...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('~/qg_dataset_supporting_facts/hotpot_train_v1.1.csv')\n",
    "train = train[:10000]\n",
    "valid = pd.read_csv('~/qg_dataset_supporting_facts/hotpot_dev_distractor_v1.csv')\n",
    "valid = valid[:1000]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-IgF44jMFPY"
   },
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL = 't5-base'\n",
    "DIR = \"question_generator/\"\n",
    "BATCH_SIZE = 1\n",
    "SEQ_LENGTH = 512\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "\n",
    "tokenizer.add_special_tokens(\n",
    "    {'additional_special_tokens': ['<answer>', '<context>']}\n",
    ")\n",
    "class QGDataset(Dataset):\n",
    "    def __init__(self, csv):\n",
    "        self.df = csv\n",
    "\n",
    "    def __len__(self):\n",
    "         return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):   \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        row = self.df.iloc[idx, 1:]       \n",
    "\n",
    "        encoded_text = tokenizer(\n",
    "            row['text'], \n",
    "            padding=True, \n",
    "            max_length=SEQ_LENGTH,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        encoded_text['input_ids'] = torch.squeeze(encoded_text['input_ids'])\n",
    "        encoded_text['attention_mask'] = torch.squeeze(encoded_text['attention_mask'])\n",
    "\n",
    "        encoded_question = tokenizer(\n",
    "            row['question'],\n",
    "            padding=True,\n",
    "            max_length=SEQ_LENGTH,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        encoded_question['input_ids'] = torch.squeeze(encoded_question['input_ids'])\n",
    "\n",
    "        return (encoded_text.to(device), encoded_question.to(device))\n",
    "\n",
    "train_set = QGDataset(train)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_set = QGDataset(valid)\n",
    "valid_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJrb9kYNz_wz"
   },
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "EPOCHS = 20\n",
    "LOG_INTERVAL = 5000\n",
    "\n",
    "config = T5Config(decoder_start_token_id=tokenizer.pad_token_id)\n",
    "model = T5ForConditionalGeneration(config).from_pretrained(PRETRAINED_MODEL)\n",
    "model.resize_token_embeddings(len(tokenizer)) # to account for new special tokens\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rcfRh2JC0CF1"
   },
   "outputs": [],
   "source": [
    "SAVED_MODEL_PATH = \"/home2/samyak.ja/qg_dataset/model_hotpot.pth\"\n",
    "TEMP_SAVE_PATH = \"/home2/samyak.ja/qg_dataset/model_hotpot.pth\"\n",
    "\n",
    "def train(epoch, best_val_loss):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for batch_index, batch in enumerate(train_loader):\n",
    "        data, target = batch\n",
    "        optimizer.zero_grad()\n",
    "        masked_labels = mask_label_padding(target['input_ids'])\n",
    "        output = model(\n",
    "            input_ids=data['input_ids'],\n",
    "            attention_mask=data['attention_mask'],\n",
    "            labels=masked_labels\n",
    "        )\n",
    "        loss = output[0]\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch_index % LOG_INTERVAL == 0 and batch_index > 0:\n",
    "            cur_loss = total_loss / LOG_INTERVAL\n",
    "            print('| epoch {:3d} | ' \n",
    "                  '{:5d}/{:5d} batches | '\n",
    "                  'loss {:5.2f}'.format(\n",
    "                    epoch, \n",
    "                    batch_index, len(train_loader), \n",
    "                    cur_loss))\n",
    "            save(\n",
    "                TEMP_SAVE_PATH,\n",
    "                epoch, \n",
    "                model.state_dict(), \n",
    "                optimizer.state_dict(), \n",
    "                best_val_loss\n",
    "            )\n",
    "            total_loss = 0\n",
    "\n",
    "def evaluate(eval_model, data_loader):\n",
    "    eval_model.eval()\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for batch_index, batch in enumerate(data_loader):\n",
    "            data, target = batch\n",
    "            masked_labels = mask_label_padding(target['input_ids'])\n",
    "            output = eval_model(\n",
    "                input_ids=data['input_ids'],\n",
    "                attention_mask=data['attention_mask'],\n",
    "                labels=masked_labels\n",
    "            )\n",
    "            total_loss += output[0].item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def mask_label_padding(labels):\n",
    "    MASK_ID = -100\n",
    "    labels[labels==tokenizer.pad_token_id] = MASK_ID\n",
    "    return labels\n",
    "\n",
    "def save(path, epoch, model_state_dict, optimizer_state_dict, loss):\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model_state_dict,\n",
    "            'optimizer_state_dict': optimizer_state_dict,\n",
    "            'best_loss': loss,\n",
    "            }, path)\n",
    "\n",
    "def load(path):\n",
    "    return torch.load(path)\n",
    "\n",
    "def print_line():\n",
    "    LINE_WIDTH = 60\n",
    "    print('-' * LINE_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9J13rDps2QIu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "| Before training | valid loss  4.00\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "best_model = None\n",
    "\n",
    "val_loss = evaluate(model, valid_loader)\n",
    "print_line()\n",
    "print('| Before training | valid loss {:5.2f}'.format(\n",
    "    val_loss)\n",
    ")\n",
    "print_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9J13rDps2QIu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  5000/10000 batches | loss  3.21\n",
      "------------------------------------------------------------\n",
      "| end of epoch   1 | valid loss  2.72\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n",
      "| epoch   2 |  5000/10000 batches | loss  2.83\n",
      "------------------------------------------------------------\n",
      "| end of epoch   2 | valid loss  2.55\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n",
      "| epoch   3 |  5000/10000 batches | loss  2.67\n",
      "------------------------------------------------------------\n",
      "| end of epoch   3 | valid loss  2.43\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n",
      "| epoch   4 |  5000/10000 batches | loss  2.58\n",
      "------------------------------------------------------------\n",
      "| end of epoch   4 | valid loss  2.33\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n",
      "| epoch   5 |  5000/10000 batches | loss  2.51\n",
      "------------------------------------------------------------\n",
      "| end of epoch   5 | valid loss  2.25\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n",
      "| epoch   6 |  5000/10000 batches | loss  2.43\n",
      "------------------------------------------------------------\n",
      "| end of epoch   6 | valid loss  2.19\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n",
      "| epoch   7 |  5000/10000 batches | loss  2.36\n",
      "------------------------------------------------------------\n",
      "| end of epoch   7 | valid loss  2.15\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n",
      "| epoch   8 |  5000/10000 batches | loss  2.33\n",
      "------------------------------------------------------------\n",
      "| end of epoch   8 | valid loss  2.12\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n",
      "| epoch   9 |  5000/10000 batches | loss  2.28\n",
      "------------------------------------------------------------\n",
      "| end of epoch   9 | valid loss  2.10\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n",
      "| epoch  10 |  5000/10000 batches | loss  2.26\n",
      "------------------------------------------------------------\n",
      "| end of epoch  10 | valid loss  2.08\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n",
      "| epoch  11 |  5000/10000 batches | loss  2.23\n",
      "------------------------------------------------------------\n",
      "| end of epoch  11 | valid loss  2.05\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n",
      "| epoch  12 |  5000/10000 batches | loss  2.19\n",
      "------------------------------------------------------------\n",
      "| end of epoch  12 | valid loss  2.03\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n",
      "| epoch  13 |  5000/10000 batches | loss  2.20\n",
      "------------------------------------------------------------\n",
      "| end of epoch  13 | valid loss  2.02\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n",
      "| epoch  14 |  5000/10000 batches | loss  2.17\n",
      "------------------------------------------------------------\n",
      "| end of epoch  14 | valid loss  2.00\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n",
      "| epoch  15 |  5000/10000 batches | loss  2.15\n",
      "------------------------------------------------------------\n",
      "| end of epoch  15 | valid loss  1.99\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n",
      "| epoch  16 |  5000/10000 batches | loss  2.13\n",
      "------------------------------------------------------------\n",
      "| end of epoch  16 | valid loss  1.97\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n",
      "| epoch  17 |  5000/10000 batches | loss  2.13\n",
      "------------------------------------------------------------\n",
      "| end of epoch  17 | valid loss  1.96\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n",
      "| epoch  18 |  5000/10000 batches | loss  2.10\n",
      "------------------------------------------------------------\n",
      "| end of epoch  18 | valid loss  1.95\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n",
      "| epoch  19 |  5000/10000 batches | loss  2.08\n",
      "------------------------------------------------------------\n",
      "| end of epoch  19 | valid loss  1.93\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n",
      "| epoch  20 |  5000/10000 batches | loss  2.08\n",
      "------------------------------------------------------------\n",
      "| end of epoch  20 | valid loss  1.92\n",
      "------------------------------------------------------------\n",
      "| Model saved.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "\n",
    "    train(epoch, best_val_loss)\n",
    "    val_loss = evaluate(model, valid_loader)\n",
    "    print_line()\n",
    "    print('| end of epoch {:3d} | valid loss {:5.2f}'.format(\n",
    "        epoch,\n",
    "        val_loss)\n",
    "    )\n",
    "    print_line()\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "        save(\n",
    "             SAVED_MODEL_PATH,\n",
    "             epoch, \n",
    "             model.state_dict(), \n",
    "             optimizer.state_dict(), \n",
    "             best_val_loss\n",
    "        )\n",
    "        print(\"| Model saved.\")\n",
    "        print_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"/home2/samyak.ja/qg_dataset/model_hotpot_last.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "md2 = torch.load(\"/home2/samyak.ja/qg_dataset_supporting_facts/model_hotpot_last.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = evaluate(md2, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Before training | valid loss  1.92\n"
     ]
    }
   ],
   "source": [
    "print('| Before training | valid loss {:5.2f}'.format(\n",
    "    val_loss)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(review_text, model, device):\n",
    "    encoded_text = tokenizer(\n",
    "            review_text, \n",
    "            padding=True, \n",
    "            max_length=SEQ_LENGTH,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "    input_ids = encoded_text['input_ids']\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids)\n",
    "    decoded_string = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(decoded_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = \"<answer> a fusional language <context> Typologically, Estonian represents a transitional form from an agglutinating language to a fusional language. The canonical word order is SVO (subject–verb–object).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estonian is a transitional form from an agglutinating language to what\n"
     ]
    }
   ],
   "source": [
    "inference(review_text, md2, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNkFJbYAaLQ9Q2ylMwrLSAk",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1Dv4wvUk6kl0WGFBxf2zb2W_3DDzwBLe8",
   "name": "QG_T5_training.ipynb",
   "provenance": [
    {
     "file_id": "1fjUac5wqsbl4kdfR6XRD0Zor3TfAg-fe",
     "timestamp": 1592456064028
    },
    {
     "file_id": "1y_8MTWmQnKalcdTQNLSZaoWN2KuAmUC5",
     "timestamp": 1591767629922
    },
    {
     "file_id": "1CIlJj2br71COiwuF4ZLWJPnMNgu0Z3u5",
     "timestamp": 1590466302923
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
