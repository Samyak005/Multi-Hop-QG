{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FvBm_K5WnVj9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UDaysJyJytAs"
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config,  AutoTokenizer, AutoModelWithLMHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzW_zmk2qFHG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.8\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a7a06935542990198eaf050</td>\n",
       "      <td>Which magazine was started first Arthur's Maga...</td>\n",
       "      <td>&lt;answer&gt; Arthur's Magazine &lt;context&gt; Arthur's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a879ab05542996e4f30887e</td>\n",
       "      <td>The Oberoi family is part of a hotel company t...</td>\n",
       "      <td>&lt;answer&gt; Delhi &lt;context&gt; The Oberoi family is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a8d7341554299441c6b9fe5</td>\n",
       "      <td>Musician and satirist Allie Goertz wrote a son...</td>\n",
       "      <td>&lt;answer&gt; President Richard Nixon &lt;context&gt; All...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5a82171f5542990a1d231f4a</td>\n",
       "      <td>What nationality was James Henry Miller's wife?</td>\n",
       "      <td>&lt;answer&gt; American &lt;context&gt; Margaret Peggy See...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5a84dd955542997b5ce3ff79</td>\n",
       "      <td>Cadmium Chloride is slightly soluble in this c...</td>\n",
       "      <td>&lt;answer&gt; alcohol &lt;context&gt; Cadmium chloride is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Unnamed: 0  \\\n",
       "0  5a7a06935542990198eaf050   \n",
       "1  5a879ab05542996e4f30887e   \n",
       "2  5a8d7341554299441c6b9fe5   \n",
       "3  5a82171f5542990a1d231f4a   \n",
       "4  5a84dd955542997b5ce3ff79   \n",
       "\n",
       "                                            question  \\\n",
       "0  Which magazine was started first Arthur's Maga...   \n",
       "1  The Oberoi family is part of a hotel company t...   \n",
       "2  Musician and satirist Allie Goertz wrote a son...   \n",
       "3    What nationality was James Henry Miller's wife?   \n",
       "4  Cadmium Chloride is slightly soluble in this c...   \n",
       "\n",
       "                                                text  \n",
       "0  <answer> Arthur's Magazine <context> Arthur's ...  \n",
       "1  <answer> Delhi <context> The Oberoi family is ...  \n",
       "2  <answer> President Richard Nixon <context> All...  \n",
       "3  <answer> American <context> Margaret Peggy See...  \n",
       "4  <answer> alcohol <context> Cadmium chloride is...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('~/qg_dataset/hotpot_train_fullcontext_v1.1.csv')\n",
    "# train = train[40001:]\n",
    "valid = pd.read_csv('~/qg_dataset/hotpot_dev_distractor_fullcontext_v1.csv')\n",
    "valid = valid[2001:]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-IgF44jMFPY"
   },
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL = 't5-base'\n",
    "DIR = \"question_generator/\"\n",
    "BATCH_SIZE = 1\n",
    "SEQ_LENGTH = 600\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "\n",
    "tokenizer.add_special_tokens(\n",
    "    {'additional_special_tokens': ['<answer>', '<context>']}\n",
    ")\n",
    "class QGDataset(Dataset):\n",
    "    def __init__(self, csv):\n",
    "        self.df = csv\n",
    "\n",
    "    def __len__(self):\n",
    "         return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):   \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        row = self.df.iloc[idx, 1:]       \n",
    "\n",
    "        encoded_text = tokenizer(\n",
    "            row['text'], \n",
    "            padding=True, \n",
    "            max_length=SEQ_LENGTH,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        encoded_text['input_ids'] = torch.squeeze(encoded_text['input_ids'])\n",
    "        encoded_text['attention_mask'] = torch.squeeze(encoded_text['attention_mask'])\n",
    "\n",
    "        encoded_question = tokenizer(\n",
    "            row['question'],\n",
    "            padding=True,\n",
    "            max_length=SEQ_LENGTH,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        encoded_question['input_ids'] = torch.squeeze(encoded_question['input_ids'])\n",
    "\n",
    "        return (encoded_text.to(device), encoded_question.to(device))\n",
    "\n",
    "train_set = QGDataset(train)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_set = QGDataset(valid)\n",
    "valid_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJrb9kYNz_wz"
   },
   "outputs": [],
   "source": [
    "# Calculating token length\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# token_lens = []\n",
    "# for txt in train.text:\n",
    "#   tokens = tokenizer.encode(txt, max_length=1024)\n",
    "#   token_lens.append(len(tokens))\n",
    "\n",
    "# sns.distplot(token_lens)\n",
    "# plt.xlim([0, 1024]);\n",
    "# plt.xlabel('Token lengths');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rcfRh2JC0CF1"
   },
   "outputs": [],
   "source": [
    "SAVED_MODEL_PATH = \"/home2/samyak.ja/qg_dataset/model_hotpot.pth\"\n",
    "TEMP_SAVE_PATH = \"/home2/samyak.ja/qg_dataset/model_hotpot.pth\"\n",
    "\n",
    "def evaluate(eval_model, data_loader):\n",
    "    eval_model.eval()\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for batch_index, batch in enumerate(data_loader):\n",
    "            data, target = batch\n",
    "            masked_labels = mask_label_padding(target['input_ids'])\n",
    "            output = eval_model(\n",
    "                input_ids=data['input_ids'],\n",
    "                attention_mask=data['attention_mask'],\n",
    "                labels=masked_labels\n",
    "            )\n",
    "            total_loss += output[0].item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def mask_label_padding(labels):\n",
    "    MASK_ID = -100\n",
    "    labels[labels==tokenizer.pad_token_id] = MASK_ID\n",
    "    return labels\n",
    "\n",
    "def load(path):\n",
    "    return torch.load(path)\n",
    "\n",
    "def print_line():\n",
    "    LINE_WIDTH = 60\n",
    "    print('-' * LINE_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "md2 = torch.load(\"/home2/samyak.ja/qg_dataset/model_hotpot_last.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(review_text, model, device):\n",
    "    encoded_text = tokenizer(\n",
    "            review_text, \n",
    "            padding=True, \n",
    "            max_length=SEQ_LENGTH,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "    input_ids = encoded_text['input_ids']\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids)\n",
    "    decoded_string = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return decoded_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "file_output = \"/home2/samyak.ja/qg_dataset/predicted_full_context.csv\"\n",
    "csvfile = open(file_output, 'w')\n",
    "csvfile.write(\"question,predicted\"+\"\\n\")\n",
    "\n",
    "for i in range(0, len(valid)):\n",
    "    test_output= valid.iloc[i, 1]\n",
    "    review_text = valid.iloc[i, 2]\n",
    "#     print(review_text)\n",
    "    predicted = inference(review_text, md2, device)\n",
    "    line1 = test_output + \",\" + predicted\n",
    "    csvfile.write(line1+\"\\n\")\n",
    "    \n",
    "    if i%500 ==0:\n",
    "        print(i)\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNkFJbYAaLQ9Q2ylMwrLSAk",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1Dv4wvUk6kl0WGFBxf2zb2W_3DDzwBLe8",
   "name": "QG_T5_training.ipynb",
   "provenance": [
    {
     "file_id": "1fjUac5wqsbl4kdfR6XRD0Zor3TfAg-fe",
     "timestamp": 1592456064028
    },
    {
     "file_id": "1y_8MTWmQnKalcdTQNLSZaoWN2KuAmUC5",
     "timestamp": 1591767629922
    },
    {
     "file_id": "1CIlJj2br71COiwuF4ZLWJPnMNgu0Z3u5",
     "timestamp": 1590466302923
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
