{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FvBm_K5WnVj9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UDaysJyJytAs"
   },
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig,  AutoTokenizer, AutoModelWithLMHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzW_zmk2qFHG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nmc/qg/Multi-Hop-QG/bart\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a8b57f25542995d1e6f1371</td>\n",
       "      <td>Were Scott Derrickson and Ed Wood of the same ...</td>\n",
       "      <td>&lt;answer&gt; yes &lt;context&gt; Scott Derrickson (born ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a8c7595554299585d9e36b6</td>\n",
       "      <td>What government position was held by the woman...</td>\n",
       "      <td>&lt;answer&gt; Chief of Protocol &lt;context&gt; Kiss and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a85ea095542994775f606a8</td>\n",
       "      <td>What science fantasy young adult series told i...</td>\n",
       "      <td>&lt;answer&gt; Animorphs &lt;context&gt; The Hork-Bajir Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5adbf0a255429947ff17385a</td>\n",
       "      <td>Are the Laleli Mosque and Esma Sultan Mansion ...</td>\n",
       "      <td>&lt;answer&gt; no &lt;context&gt; The Laleli Mosque (Turki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5a8e3ea95542995a26add48d</td>\n",
       "      <td>The director of the romantic comedy Big Stone ...</td>\n",
       "      <td>&lt;answer&gt; Greenwich Village New York City &lt;cont...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Unnamed: 0  \\\n",
       "0  5a8b57f25542995d1e6f1371   \n",
       "1  5a8c7595554299585d9e36b6   \n",
       "2  5a85ea095542994775f606a8   \n",
       "3  5adbf0a255429947ff17385a   \n",
       "4  5a8e3ea95542995a26add48d   \n",
       "\n",
       "                                            question  \\\n",
       "0  Were Scott Derrickson and Ed Wood of the same ...   \n",
       "1  What government position was held by the woman...   \n",
       "2  What science fantasy young adult series told i...   \n",
       "3  Are the Laleli Mosque and Esma Sultan Mansion ...   \n",
       "4  The director of the romantic comedy Big Stone ...   \n",
       "\n",
       "                                                text  \n",
       "0  <answer> yes <context> Scott Derrickson (born ...  \n",
       "1  <answer> Chief of Protocol <context> Kiss and ...  \n",
       "2  <answer> Animorphs <context> The Hork-Bajir Ch...  \n",
       "3  <answer> no <context> The Laleli Mosque (Turki...  \n",
       "4  <answer> Greenwich Village New York City <cont...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valid = pd.read_csv('../processed_dataset/hotpot_dev_distractor_supporting_facts_v1.csv')\n",
    "valid = pd.read_csv('../processed_dataset/hotpot_dev_distractor_fullcontext_v1.csv')\n",
    "valid = valid[2001:]\n",
    "\n",
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-IgF44jMFPY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRETRAINED_MODEL = 'facebook/bart-base'\n",
    "SEQ_LENGTH = 600\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "\n",
    "tokenizer.add_special_tokens(\n",
    "    {'additional_special_tokens': ['<answer>', '<context>']}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# md2 = torch.load(\"model_hotpot_supporting_facts_last.pth\") # Supporting facts\n",
    "md2 = torch.load(\"model_hotpot_full_context_last.pth\") # Full context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(review_text, model, device):\n",
    "    encoded_text = tokenizer(\n",
    "            review_text, \n",
    "            padding=True, \n",
    "            max_length=SEQ_LENGTH,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "    input_ids = encoded_text['input_ids']\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids)\n",
    "    decoded_string = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return decoded_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmc/anaconda3/envs/questiongen/lib/python3.9/site-packages/transformers/generation_utils.py:1838: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  next_indices = next_tokens // vocab_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "file_output = \"predicted_supporting_facts.csv\"\n",
    "csvfile = open(file_output, 'w')\n",
    "csvfile.write(\"question,predicted\"+\"\\n\")\n",
    "\n",
    "for i in range(0, len(valid)):\n",
    "    test_output= valid.iloc[i, 1]\n",
    "    review_text = valid.iloc[i, 2]\n",
    "#     print(review_text)\n",
    "    predicted = inference(review_text, md2, device)\n",
    "    line1 = test_output + \",\" + predicted\n",
    "    csvfile.write(line1+\"\\n\")\n",
    "    \n",
    "    if i%500 ==0:\n",
    "        print(i)\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_output = \"predicted_full_context.csv\"\n",
    "csvfile = open(file_output, 'w')\n",
    "csvfile.write(\"question,predicted\"+\"\\n\")\n",
    "\n",
    "for i in range(0, len(valid)):\n",
    "    test_output= valid.iloc[i, 1]\n",
    "    review_text = valid.iloc[i, 2]\n",
    "#     print(review_text)\n",
    "    predicted = inference(review_text, md2, device)\n",
    "    line1 = test_output + \",\" + predicted\n",
    "    csvfile.write(line1+\"\\n\")\n",
    "    \n",
    "    if i%500 ==0:\n",
    "        print(i)\n",
    "csvfile.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNkFJbYAaLQ9Q2ylMwrLSAk",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1Dv4wvUk6kl0WGFBxf2zb2W_3DDzwBLe8",
   "name": "QG_T5_training.ipynb",
   "provenance": [
    {
     "file_id": "1fjUac5wqsbl4kdfR6XRD0Zor3TfAg-fe",
     "timestamp": 1592456064028
    },
    {
     "file_id": "1y_8MTWmQnKalcdTQNLSZaoWN2KuAmUC5",
     "timestamp": 1591767629922
    },
    {
     "file_id": "1CIlJj2br71COiwuF4ZLWJPnMNgu0Z3u5",
     "timestamp": 1590466302923
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
