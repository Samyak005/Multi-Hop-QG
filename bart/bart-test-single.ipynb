{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import logging\n",
    "# Transformer version 4.9.1 - Newer versions may not work.\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # The code assumes you are using GPU. Otherwise, use map_location=torch.device('cpu') in torch.load()\n",
    "print('Using device:' + str(device))\n",
    "PRETRAINED_MODEL = 'facebook/bart-base'\n",
    "SEQ_LENGTH = 600\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "\n",
    "tokenizer.add_special_tokens(\n",
    "    {'additional_special_tokens': ['<answer>', '<context>']}\n",
    ")\n",
    "\n",
    "md2 = torch.load(\"model_hotpot_supporting_facts_last.pth\", map_location=torch.device('cpu')) # Supporting facts\n",
    "# md2 = torch.load(\"model_hotpot_full_context_last.pth\") # Full context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmc/anaconda3/envs/questiongen/lib/python3.9/site-packages/transformers/generation_utils.py:1838: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  next_indices = next_tokens // vocab_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estonian represents a transitional form from what type of language?\n"
     ]
    }
   ],
   "source": [
    "def inference(review_text, model, device):\n",
    "    encoded_text = tokenizer(\n",
    "        review_text,\n",
    "        padding=True,\n",
    "        max_length=SEQ_LENGTH,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    input_ids = encoded_text['input_ids']\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids)\n",
    "    decoded_string = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    logging.debug(\"Decoded string\" + decoded_string)\n",
    "    print(decoded_string)\n",
    "\n",
    "    return decoded_string\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    review_text = \"<answer> a fusional language <context> Typologically, Estonian represents a transitional form from an agglutinating language to a fusional language. The canonical word order is SVO (subject–verb–object).\"\n",
    "    inference(review_text, md2, device)\n",
    "\n",
    "\n",
    "def get_inference(answer, context):\n",
    "    valuation_text = \"<answer> \" + answer + \" <context> \" + context\n",
    "    return inference(valuation_text, md2, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is a dolphin Nirmal or Pavani?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Who is a dolphin Nirmal or Pavani?'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text = \"<answer> Pavani <context> Pavani is the prime minister of the world's biggest democracy.  World's biggest democracy is not china. \\\n",
    "                World's biggest democracy is India. Nirmal lives in Kerala. Nirmal loves ocean. Pavani is a dolphin.\"\n",
    "inference(review_text, md2, device)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6c35795358edc5b64ae0ebcb5f6a08281606967d5b1e48ada8a049182cdadaf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('questiongen': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
